{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from siphon.ncss import NCSS\n",
    "from netCDF4 import Dataset, num2date\n",
    "from metpy.plots import StationPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_neighbor(xi,yi,xk,yk,phi):\n",
    "    grid = np.zeros((len(yi),len(xi)))\n",
    "    for e in range(len(xi)):\n",
    "        for f in range(len(yi)):\n",
    "            dum_dist = 10000000.\n",
    "            for g in range(len(xk)):\n",
    "                dist = (((xk[g]-xi[e])**2) + ((yk[g]-yi[f])**2))**(0.5)\n",
    "                if (dist <= dum_dist):\n",
    "                    dum_dist = dist\n",
    "                    dum_phi = phi[g]\n",
    "                elif (dist == dum_dist):\n",
    "                    dum_phi = (dum_phi + phi[g])/2.\n",
    "            grid[f,e] = dum_phi\n",
    "    return gaussian_filter(grid,sigma=2)\n",
    "\n",
    "def barnes_guess(x_i,y_i,x_k,y_k,phi_0,roi):\n",
    "    grid = np.zeros((len(y_i),len(x_i)))\n",
    "    # Loop through the grid and update the initial grid with the observations\n",
    "    for l in range(len(x_i)):\n",
    "        for m in range(len(y_i)):\n",
    "            sum_weight = 0.\n",
    "            num_weight = 0.\n",
    "            weight     = 0.\n",
    "            for p in range(len(phi_0)): # Loop for the observations\n",
    "                # Determining the distance between the observation and a grid point\n",
    "                rad2 = ((x_k[p]-x_i[l])**2 + (y_k[p]-y_i[m])**2)**(1/2)\n",
    "                weight = np.exp(-(rad2**2)/(roi**2))\n",
    "                sum_weight+=weight\n",
    "                weight_phi = weight * phi_0[p] # \n",
    "                num_weight+=weight_phi\n",
    "            grid[m,l] = num_weight/sum_weight\n",
    "    return gaussian_filter(grid, sigma=2)\n",
    "\n",
    "def cressman(x_i, y_i, x_k, y_k, phi_0, guess_field):\n",
    "    # Estimate of grid at Obs points\n",
    "    h = np.zeros(len(phi_0)).astype('float')\n",
    "\n",
    "    # Assimilated Grid\n",
    "    grid = np.zeros((len(y_i),len(x_i)))\n",
    "    #print(grid.shape)\n",
    "\n",
    "    # Begin the Cressman Scheme, doing three passes with Radius of Influence (roi)\n",
    "    # of 80, 50, and 40 grid points\n",
    "    for i in [1,2,3]:\n",
    "        if (i == 1):\n",
    "            roi = 15.**2.\n",
    "        elif (i == 2):\n",
    "            roi = 10.**2.\n",
    "        else:\n",
    "            roi = 5.**2.\n",
    "\n",
    "            # Calculating the values of the grid at the observation points through simple linear interpolation\n",
    "        for p in range(len(phi_0)):\n",
    "            if (np.int(y_k[p]) in y_i) & ((np.int(x_k[p]) in x_i)):\n",
    "                a = np.where(y_i == np.int(y_k[p]))[0][0]\n",
    "                a2 = np.abs(y_i[a] - (y_k[p]))\n",
    "                b = np.where(x_i == np.int(x_k[p]))[0][0]\n",
    "                b2 = np.abs(x_i[b] - (x_k[p]))\n",
    "                h[p] = (((guess_field[a,b]*(1-b2)+guess_field[a,b+1]*b2))*(1-a2) +\n",
    "                        ((guess_field[a-1,b]*(1-b2)+guess_field[a-1,b+1]*b2))*(a2))\n",
    "            else:\n",
    "                h[p] = phi_0[p]\n",
    "\n",
    "    # Loop through the grid and update the initial grid with the observations\n",
    "        for l in range(len(x_i)):\n",
    "            for m in range(len(y_i)):\n",
    "                sum_weight = 0.\n",
    "                num_weight = 0.\n",
    "                weight     = 0.\n",
    "                for p in range(len(phi_0)): # Loop for the observations\n",
    "                    # Determining the distance between the observation and a grid point\n",
    "                    rad2 = ((x_k[p]-x_i[l])**2 + (y_k[p]-y_i[m])**2)\n",
    "                    #print(dist2)\n",
    "                    if (rad2 <= roi):\n",
    "                        weight = (roi - rad2)/(roi + rad2) # Setting the weight if within the roi\n",
    "                    else:\n",
    "                        weight = 0. # Setting the weight of the ob to zero if outside the roi\n",
    "                    sum_weight+=weight\n",
    "                    weight_phi = weight * (phi_0[p] - h[p]) # \n",
    "                    num_weight+=weight_phi\n",
    "                if sum_weight > 0:\n",
    "                    grid[m,l] = guess_field[m,l] + (num_weight/sum_weight) # Updating the grid\n",
    "                else:\n",
    "                    grid[m,l] = guess_field[m,l]\n",
    "\n",
    "\n",
    "\n",
    "        guess_field = grid   # Saving the grid to use in the next iteration\n",
    "    return grid\n",
    "\n",
    "def barnes(x_i, y_i, x_k, y_k, phi_0, guess_field):\n",
    "    # Estimate of grid at Obs points\n",
    "    h = np.zeros(len(phi_0)).astype('float')\n",
    "\n",
    "    # Assimilated Grid\n",
    "    grid = np.zeros((len(y_i),len(x_i)))\n",
    "\n",
    "    # Begin the Cressman Scheme, doing three passes with Radius of Influence (roi)\n",
    "    # of 80, 50, and 40 grid points\n",
    "    roi = 5\n",
    "    for i in [1,2]:\n",
    "        if (i == 1):\n",
    "            gamma = 1\n",
    "        elif (i == 2):\n",
    "            gamma = 0.33\n",
    "\n",
    "        # Calculating the values of the grid at the observation points through simple linear interpolation\n",
    "        for p in range(len(phi_0)):\n",
    "            if (np.int(y_k[p]) in y_i) & ((np.int(x_k[p]) in x_i)):\n",
    "                a = np.where(y_i == np.int(y_k[p]))[0][0]\n",
    "                a2 = np.abs(y_i[a] - (y_k[p]))\n",
    "                b = np.where(x_i == np.int(x_k[p]))[0][0]\n",
    "                b2 = np.abs(x_i[b] - (x_k[p]))\n",
    "                h[p] = (((guess_field[a,b]*(1-b2)+guess_field[a,b+1]*b2))*(1-a2) +\n",
    "                        ((guess_field[a-1,b]*(1-b2)+guess_field[a-1,b+1]*b2))*(a2))\n",
    "            else:\n",
    "                h[p] = phi_0[p]\n",
    "\n",
    "        # Loop through the grid and update the initial grid with the observations\n",
    "        for l in range(len(x_i)):\n",
    "            for m in range(len(y_i)):\n",
    "                sum_weight = 0.\n",
    "                num_weight = 0.\n",
    "                weight     = 0.\n",
    "                for p in range(len(phi_0)): # Loop for the observations\n",
    "                    # Determining the distance between the observation and a grid point\n",
    "                    rad2 = ((x_k[p]-x_i[l])**2 + (y_k[p]-y_i[m])**2)**(1/2)\n",
    "                    weight = np.exp(-(rad2**2)/(gamma*roi**2))\n",
    "                    sum_weight+=weight\n",
    "                    weight_phi = weight * (phi_0[p] - h[p]) # \n",
    "                    num_weight+=weight_phi\n",
    "                if sum_weight > 0:\n",
    "                    grid[m,l] = guess_field[m,l] + (num_weight/sum_weight) # Updating the grid\n",
    "                else:\n",
    "                    grid[m,l] = guess_field[m,l]\n",
    "\n",
    "\n",
    "\n",
    "        guess_field = grid   # Saving the grid to use in the next iteration\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get the True Data that occurred\n",
    "ncss = NCSS('http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/Global_onedeg_ana/'+\n",
    "            'GFS_Global_onedeg_ana_20171209_1200.grib2')\n",
    "\n",
    "query = ncss.query()\n",
    "\n",
    "query.variables('Temperature_isobaric',\n",
    "                'Geopotential_height_isobaric',\n",
    "                'u-component_of_wind_isobaric',\n",
    "                'v-component_of_wind_isobaric')\n",
    "query.add_lonlat().vertical_level(50000)\n",
    "query.lonlat_box(north=URLat,south=LLLat,west=LLLon,east=URLon)\n",
    "\n",
    "data = ncss.get_data(query)\n",
    "\n",
    "gfs_hght_500 = data.variables['Geopotential_height_isobaric'][:].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Time: 2017-12-09 12:00:00\n"
     ]
    }
   ],
   "source": [
    "    # Data from https://ruc.noaa.gov/raobs/ mandatory levels for U.S.\n",
    "    # Min Lat: 20 N\n",
    "    # Max Lat: 70 N\n",
    "    # Min Lon: -145 E\n",
    "    # Max Lat: -50 E\n",
    "\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    filename = '/Users/kgoebber/nwp/20171209_12_RAOB_data.txt'\n",
    "\n",
    "    file_data = open(filename, 'r')\n",
    "\n",
    "    date = []\n",
    "    lat = []\n",
    "    lon = []\n",
    "    stid = []\n",
    "    hght_500 = []\n",
    "\n",
    "    for line in file_data.readlines():\n",
    "        tmp = line.split()\n",
    "        if (tmp[0] == '254'):\n",
    "            _, hour, day, month, year = tmp\n",
    "            date_string = '%d%s%02d%02d'%(int(year),month,int(day),int(hour))\n",
    "            date.append(datetime.strptime(date_string,'%Y%b%d%H'))\n",
    "        elif (tmp[0] == '1'):\n",
    "            if (len(tmp) == 6):\n",
    "                west_test = re.split(' | N |S |N|S|W', tmp[3])\n",
    "                if (len(west_test) == 3):\n",
    "                    west = -1\n",
    "                else:\n",
    "                    west = 1\n",
    "                south_test = re.split(' | N|N|E|W', tmp[3])\n",
    "                if (len(south_test) != 3):\n",
    "                    south = -1\n",
    "                else:\n",
    "                    south = 1\n",
    "                tlat, tlon = re.split(' | N |S |N|S|E|W', tmp[3])[:2]\n",
    "            if (len(tmp) == 7):\n",
    "                west_test = re.split('W', tmp[4])\n",
    "                if (len(west_test) == 2):\n",
    "                    west = -1\n",
    "                else:\n",
    "                    west = 1\n",
    "                south_test = re.split('N', tmp[3])\n",
    "                if (len(south_test) == 2):\n",
    "                    south = 1\n",
    "                else:\n",
    "                    south = -1\n",
    "                tlat = re.split('N|S', tmp[3])[0]\n",
    "                tlon = re.split('E|W', tmp[4])[0]\n",
    "            lat.append(south*float(tlat))\n",
    "            lon.append(west*float(tlon))\n",
    "        elif (tmp[0] == '3'):\n",
    "            stid.append(tmp[1])\n",
    "        elif (tmp[0] == '4'):\n",
    "            if (float(tmp[1])/10. == 500):\n",
    "                hght_500.append(float(tmp[2]))\n",
    "\n",
    "    # Set up geographic region\n",
    "    LLLon = -140.\n",
    "    LLLat = 19.\n",
    "    URLon = -50.\n",
    "    URLat = 70\n",
    "\n",
    "    # Set values for assimilation grid (1x1 degree lat/lon)\n",
    "    lats = np.arange(URLat,LLLat-1,-1)\n",
    "    lons = np.arange(LLLon,URLon+1,1)\n",
    "\n",
    "    # Bring in Actual GFS Analysis\n",
    "    actual_gfs_500 = Dataset('/Users/kgoebber/python_notebooks/gfsanl_3_20171209_1200_000.nc','r')\n",
    "    actual_time = actual_gfs_500.variables['time']\n",
    "    actual_vtimes = num2date(actual_time[:],units=actual_time.units)\n",
    "    print('Analysis Time: {}'.format(actual_vtimes[0]))\n",
    "    actual_hght_500 = actual_gfs_500.variables['Geopotential_height'][0,0,:,:]\n",
    "    gfs_lats = actual_gfs_500.variables['lat'][:]\n",
    "    gfs_lons = actual_gfs_500.variables['lon'][:]\n",
    "    iULat = list(gfs_lats).index(URLat)\n",
    "    iLLat = list(gfs_lats).index(LLLat)+1\n",
    "    iULon = list(gfs_lons).index(360+URLon)+1\n",
    "    iLLon = list(gfs_lons).index(360+LLLon)\n",
    "    gfs_hght_500 = actual_hght_500[iULat:iLLat,iLLon:iULon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(FG_type):\n",
    "    clons, clats = np.meshgrid(lons,lats)\n",
    "    \n",
    "    if FG_type == 'gfs':\n",
    "        # Get First Guess field from 12 hour forecast of GFS\n",
    "        data_gfs_first_guess = Dataset('/Users/kgoebber/python_notebooks/gfs_3_20171209_0000_012.nc','r')\n",
    "        FG_time = data_gfs_first_guess.variables['time']\n",
    "        FG_vtimes = num2date(FG_time[:],units=FG_time.units)\n",
    "        FG_hght_500 = data_gfs_first_guess.variables['Geopotential_height'][0,0,:,:]\n",
    "        FG = FG_hght_500[iULat:iLLat,iLLon:iULon]\n",
    "        FG_title = 'GFS Fcst'\n",
    "    elif FG_type == 'NN':\n",
    "        FG = near_neighbor(lons,lats,lon,lat,hght_500)\n",
    "        FG_title = 'Nearest Neighbor'\n",
    "    # Set firstguess field for Cressman Scheme\n",
    "    # Use the Nearest Neighbor approach to initially fill the grid\n",
    "    elif FG_type == 'barnes':\n",
    "        FG = barnes_guess(lons,lats,lon,lat,hght_500,3)\n",
    "        FG_title = 'Barnes'\n",
    "    \n",
    "    # Generate Analyzed Fields with Cressman and Barnes\n",
    "    cress_hght_500 = cressman(lons,lats,lon,lat,hght_500,FG)\n",
    "    barnes_hght_500 = barnes(lons,lats,lon,lat,hght_500,FG)\n",
    "\n",
    "    print(\"First Guess Field: {}\".format(FG_type))\n",
    "    print(\"First Guess Error: {:.2f}\".format(np.average(gfs_hght_500-FG)))\n",
    "    print(\"Average Cressman Analysis Error: {:.2f}\".format(np.average(gfs_hght_500-cress_hght_500)))\n",
    "    print(\"Average Barnes Analysis Error: {:.2f}\".format(np.average(gfs_hght_500-barnes_hght_500)))\n",
    "    \n",
    "    # Get data to plot state and province boundaries\n",
    "    states_provinces = cfeat.NaturalEarthFeature(\n",
    "            category='cultural',\n",
    "            name='admin_1_states_provinces_lakes',\n",
    "            scale='50m',\n",
    "            facecolor='none')\n",
    "\n",
    "    plotcrs = ccrs.PlateCarree()\n",
    "\n",
    "    fig = plt.figure(1,figsize=(20,15))\n",
    "    ax = fig.add_subplot(211,projection=plotcrs,label='top')\n",
    "\n",
    "    ax.set_extent([-130, -65, 20, 50])\n",
    "    ax.coastlines('50m')\n",
    "\n",
    "    ax.add_feature(states_provinces,edgecolor='black',linewidth=0.5)\n",
    "    # Set up station plotting using only every third element from arrays for plotting\n",
    "    stationplot = StationPlot(ax, lon, lat, transform=ccrs.PlateCarree(), fontsize=12)\n",
    "    stationplot.plot_parameter('C', hght_500)\n",
    "\n",
    "    cs = ax.contour(clons,clats,cress_hght_500,np.arange(0,7000,60),colors='r',linestyles='dashed')\n",
    "    plt.clabel(cs,fmt='%d')\n",
    "    cs3 = ax.contour(clons,clats,gfs_hght_500,np.arange(0,7000,60),colors='k')\n",
    "    plt.clabel(cs3,fmt='%d')\n",
    "\n",
    "    plt.title('500-hPa Geopotential Heights (Actual Analysis - black; Cressman Analysis - red)',loc='left')\n",
    "    plt.title(date[0], loc='right')\n",
    "\n",
    "    ax2 = fig.add_subplot(212, projection=plotcrs,label='bottom')\n",
    "    ax2.set_extent([-130, -65, 20, 50])\n",
    "    ax2.coastlines('50m')\n",
    "    ax2.add_feature(states_provinces,edgecolor='black',linewidth=0.5)\n",
    "    # Set up station plotting using only every third element from arrays for plotting\n",
    "    stationplot = StationPlot(ax2, lon, lat, transform=ccrs.PlateCarree(), fontsize=12)\n",
    "    stationplot.plot_parameter('C', hght_500)\n",
    "\n",
    "    cs2 = ax2.contour(clons,clats,barnes_hght_500,np.arange(0,7000,60),colors='b',linestyles='dotted')\n",
    "    plt.clabel(cs2,fmt='%d')\n",
    "    cs4 = ax2.contour(clons,clats,gfs_hght_500,np.arange(0,7000,60),colors='k')\n",
    "    plt.clabel(cs4,fmt='%d')\n",
    "\n",
    "    plt.title('500-hPa Geopotential Heights (Actual Analysis - black; Barnes Analysis - blue)',loc='left')\n",
    "    plt.title(date[0], loc='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b9f419efe64f1b92e15ec57013115e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description='First Guess: ', options={'GFS Fcst': 'gfs', 'Nearest Neighbor': 'NN', 'Barnes': 'barnes'}, value='gfs'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "\n",
    "interact(plot, FG_type = widgets.Dropdown(options={'GFS Fcst':'gfs','Nearest Neighbor':'NN','Barnes':'barnes'},\n",
    "                                          description='First Guess: '));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
